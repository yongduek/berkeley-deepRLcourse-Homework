{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yndkrun.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import gym\n",
    "from gym import wrappers\n",
    "import os.path as osp\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# these files are in your folder.\n",
    "import dqn\n",
    "from dqn_utils import *\n",
    "from atari_wrappers import *  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def atari_model(img_in, num_actions, scope, reuse=False):\n",
    "    # as described in https://storage.googleapis.com/deepmind-data/assets/papers/DeepMindNature14236Paper.pdf\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "        out = img_in\n",
    "        with tf.variable_scope(\"convnet\"):\n",
    "            # original architecture\n",
    "            out = layers.convolution2d(out, num_outputs=32, kernel_size=8, stride=4, activation_fn=tf.nn.relu)\n",
    "            out = layers.convolution2d(out, num_outputs=64, kernel_size=4, stride=2, activation_fn=tf.nn.relu)\n",
    "            out = layers.convolution2d(out, num_outputs=64, kernel_size=3, stride=1, activation_fn=tf.nn.relu)\n",
    "        out = layers.flatten(out)\n",
    "        with tf.variable_scope(\"action_value\"):\n",
    "            out = layers.fully_connected(out, num_outputs=512,         activation_fn=tf.nn.relu)\n",
    "            out = layers.fully_connected(out, num_outputs=num_actions, activation_fn=None)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-4-b9047d793c22>, line 51)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-b9047d793c22>\"\u001b[0;36m, line \u001b[0;32m51\u001b[0m\n\u001b[0;31m    #\u001b[0m\n\u001b[0m     \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "def atari_learn(env,\n",
    "                session,\n",
    "                num_timesteps):\n",
    "    # This is just a rough estimate\n",
    "    num_iterations = float(num_timesteps) / 4.0\n",
    "\n",
    "    lr_multiplier = 1.0\n",
    "    lr_schedule = PiecewiseSchedule([\n",
    "                                         (0,                   1e-4 * lr_multiplier),\n",
    "                                         (num_iterations / 10, 1e-4 * lr_multiplier),\n",
    "                                         (num_iterations / 2,  5e-5 * lr_multiplier),\n",
    "                                    ],\n",
    "                                    outside_value=5e-5 * lr_multiplier)\n",
    "    optimizer = dqn.OptimizerSpec(\n",
    "        constructor=tf.train.AdamOptimizer,\n",
    "        kwargs=dict(epsilon=1e-4),\n",
    "        lr_schedule=lr_schedule\n",
    "    )\n",
    "\n",
    "    def stopping_criterion(env, t):\n",
    "        # notice that here t is the number of steps of the wrapped env,\n",
    "        # which is different from the number of steps in the underlying env\n",
    "        return get_wrapper_by_name(env, \"Monitor\").get_total_steps() >= num_timesteps\n",
    "\n",
    "    exploration_schedule = PiecewiseSchedule(\n",
    "        [\n",
    "            (0, 1.0),\n",
    "            (1e6, 0.1),\n",
    "            (num_iterations / 2, 0.01),\n",
    "        ], outside_value=0.01\n",
    "    )\n",
    "'''\n",
    "    dqn.learn(\n",
    "        env,\n",
    "        q_func=atari_model,\n",
    "        optimizer_spec=optimizer,\n",
    "        session=session,\n",
    "        exploration=exploration_schedule,\n",
    "        stopping_criterion=stopping_criterion,\n",
    "        replay_buffer_size=1000000,\n",
    "        batch_size=32,\n",
    "        gamma=0.99,\n",
    "        learning_starts=50000,\n",
    "        learning_freq=4,\n",
    "        frame_history_len=4,\n",
    "        target_update_freq=10000,\n",
    "        grad_norm_clipping=10\n",
    "    )\n",
    "''''''\n",
    "    env.close()\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Recording and uploading results: ``gym.wrappers.Monitor()``\n",
    "\n",
    "https://gym.openai.com/docs\n",
    "\n",
    "Gym makes it simple to record your algorithm's performance on an environment, as well as to take videos of your algorithm's learning. Just wrap your environment with a Monitor Wrapper as follows:\n",
    "\n",
    "```\n",
    "import gym\n",
    "from gym import wrappers\n",
    "env = gym.make('CartPole-v0')\n",
    "env = wrappers.Monitor(env, '/tmp/cartpole-experiment-1')\n",
    "for i_episode in range(20):\n",
    "    observation = env.reset()\n",
    "    for t in range(100):\n",
    "        env.render()\n",
    "        print(observation)\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break\n",
    "```\n",
    "\n",
    "This will log your algorithm's performance to the provided directory. The Monitor is fairly sophisticated, and supports multiple instances of an environment writing to a single directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_available_gpus():\n",
    "    from tensorflow.python.client import device_lib\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.physical_device_desc for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "def set_global_seeds(i):\n",
    "    try:\n",
    "        import tensorflow as tf\n",
    "    except ImportError:\n",
    "        pass\n",
    "    else:\n",
    "        tf.set_random_seed(i) \n",
    "    np.random.seed(i)\n",
    "    random.seed(i)\n",
    "\n",
    "def get_session():\n",
    "    tf.reset_default_graph()\n",
    "    tf_config = tf.ConfigProto(\n",
    "        inter_op_parallelism_threads=1,\n",
    "        intra_op_parallelism_threads=1)\n",
    "    session = tf.Session(config=tf_config)\n",
    "    print(\"AVAILABLE GPUS: \", get_available_gpus())\n",
    "    return session\n",
    "\n",
    "def get_env(task, seed):\n",
    "    env_id = task.env_id\n",
    "\n",
    "    env = gym.make(env_id)\n",
    "\n",
    "    set_global_seeds(seed)\n",
    "    env.seed(seed)\n",
    "\n",
    "    expt_dir = '/tmp/hw3_vid_dir2/'\n",
    "    env = wrappers.Monitor(env, osp.join(expt_dir, \"gym\"), force=True)\n",
    "    env = wrap_deepmind(env) # see atari_wrappers.py\n",
    "\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Get Atari games.\n",
    "    benchmark = gym.benchmark_spec('Atari40M')\n",
    "\n",
    "    # Change the index to select a different game.\n",
    "    task = benchmark.tasks[3]\n",
    "\n",
    "    # Run training\n",
    "    seed = 0 # Use a seed of zero (you may want to randomize the seed!)\n",
    "    env = get_env(task, seed)\n",
    "    session = get_session()\n",
    "    atari_learn(env, session, num_timesteps=task.max_timesteps)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
